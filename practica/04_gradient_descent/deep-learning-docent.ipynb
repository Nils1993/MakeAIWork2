{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783305be-8517-4058-a458-23956ad0be80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7ed7f-ad3f-46cd-9b05-b424251cf191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets\n",
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d5d78-a879-492f-ab43-d12b79c0af6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb9983-c570-4454-8195-6c64977c659c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bronnen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3a8dc-4d1a-46aa-b4e9-89c24cfb16f0",
   "metadata": {},
   "source": [
    "**Fast.ai**\n",
    "\n",
    "+ [Practical Deep Learning for Coders](https://course.fast.ai/)\n",
    "+ [Neural net foundations](https://course.fast.ai/Lessons/lesson3.html)\n",
    "\n",
    "**CodingTrain**:\n",
    "\n",
    "+ [Linear Regression with Gradient Descent](https://www.youtube.com/watch?v=L-Lsfu4ab74)\n",
    "+ [Mathematics of Gradient Descent](https://www.youtube.com/watch?v=jc2IthslyzM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eebb08-e24b-4f99-a22b-2ae89d0ce43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336d81e-3fbe-405b-8924-5fb9d995dbc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b49e5-4e09-47c1-bc79-5819674625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def preparePlot(t):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(xlim=[-10, 10], ylim=[-50, 400], xlabel='x', ylabel='y', title=t)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def plotCurve(x, y, scatter):\n",
    "\n",
    "    if scatter:\n",
    "        \n",
    "        plt.scatter(x, y)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        plt.plot(x, y, 'red')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def showPlot():\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5ca0e-99ce-4a7a-a222-6e2277b280af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x in range(-10, 11, 1)]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91d22a-57cf-463f-b6e6-9a35e655f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The answer to everything\n",
    "rnd.seed(42)\n",
    "\n",
    "a = 2\n",
    "b = 3\n",
    "c = -10\n",
    "\n",
    "# Prepare random data\n",
    "y = [a * x**2 + b * x + c for x in x]\n",
    "\n",
    "# Mean\n",
    "mu = 5\n",
    "\n",
    "# Define standard deviation (spread)\n",
    "sigma = 20\n",
    "\n",
    "# Prepare random data\n",
    "yNoise = [a * x**2 + b * x + c + rnd.gauss(mu, sigma) for x in x]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647d61c-33c8-4edc-b356-f57dc689aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparePlot(\"Parabool\")\n",
    "plotCurve(x,y, False)\n",
    "plotCurve(x,yNoise, True)\n",
    "showPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421b00c-3903-426c-803e-e8c4e34b48d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Doel: best fit maken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100e5ee-acbe-4f07-9ba1-307a8d64f379",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ReLU: Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf2502-27de-4664-866c-42ac0b2e4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def relu(w, b, x):\n",
    "    \n",
    "    y = w * x + b\n",
    "    \n",
    "    if y > 0:\n",
    "        \n",
    "        \n",
    "        return y\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbeb1e-71f8-405a-8d80-6c3b65abee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def manualRelu(w, b):\n",
    "    \n",
    "    rlu = [relu(w, b, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"ReLU\")\n",
    "    \n",
    "    plotCurve(x, rlu, False)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "interact(manualRelu, w=(-30,30,0.1), b=(-100,100,0.1))\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875413a-ee27-4ef3-b317-f3bf1df27441",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handmatige parabool fit met ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ed231-5941-48ad-8e64-67a9a22ab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def mse(fit):\n",
    "    \n",
    "    sse = 0\n",
    "    \n",
    "    # Sum of squared errors\n",
    "    for i in range(0, len(yNoise)):\n",
    "        \n",
    "        # Error = actual - predicted\n",
    "        err = yNoise[i] - fit[i]\n",
    "        sse += (err**2)\n",
    "    \n",
    "    # Mean squared error\n",
    "    return sse / len(yNoise)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def parabolaFit(w1, b1, w2, b2):\n",
    "    \n",
    "    fit = [relu(w1, b1, x) + relu(w2, b2, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"Som van 2 ReLUs\")\n",
    "    \n",
    "    plotCurve(x, fit, False)\n",
    "    plotCurve(x, yNoise, True)\n",
    "    \n",
    "    showPlot()\n",
    "    \n",
    "    # Our indicator\n",
    "    print(mse(fit))\n",
    "\n",
    "#------------------------------------------\n",
    "    \n",
    "interact(parabolaFit, w1=(-50,50,0.01), b1=(-100,100,0.01), w2=(-50,50,0.01), b2=(-100,100,0.01))\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e292586-9762-4918-a02a-2c8bf1112451",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf91953-511e-43a6-b997-7a3a6464d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "# Learning iterations\n",
    "epochs = 100\n",
    "\n",
    "# Learning rate\n",
    "learningRate = 1e-4\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Initial values (\"guess\")\n",
    "w1Fit = 0.0\n",
    "b1Fit = 0.0\n",
    "w2Fit = 0.0\n",
    "b2Fit = 0.0\n",
    "\n",
    "# Epochs counter\n",
    "epoch = 0\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def cost(w1, b1, w2, b2):\n",
    "    \n",
    "    sse = 0\n",
    "    \n",
    "    # Sum of squared errors\n",
    "    for i in range(0, len(yNoise)):\n",
    "        \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2) + \n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "        \n",
    "        sse += (err**2)\n",
    "    \n",
    "    # Mean squared error\n",
    "    return sse / len(yNoise)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def gradientDescent(w1, b1, w2, b2):\n",
    "    \n",
    "    # The change of our weights and biases\n",
    "    dw1 = 0\n",
    "    db1 = 0\n",
    "    \n",
    "    dw2 = 0\n",
    "    db2 = 0\n",
    "    \n",
    "    # Stochastic gradient descent\n",
    "    for i in range(0, len(yNoise)):\n",
    "    \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2)\n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "\n",
    "        # Gradient descent steps\n",
    "        dw1 -= 2 * err * x[i]\n",
    "        db1 -= 2 * err\n",
    "        \n",
    "        # Adjust with learn rate\n",
    "        w1 -= learningRate * dw1\n",
    "        b1 -= learningRate * db1\n",
    "        \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2)\n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "        \n",
    "        dw2 -= 2 * err * x[i]\n",
    "        db2 -= 2 * err\n",
    "        \n",
    "        # Adjust with learn rate\n",
    "        w2 -= learningRate * dw2\n",
    "        b2 -= learningRate * db2\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def plotFit(w1, b1, w2, b2):\n",
    "    \n",
    "    fit = [relu(w1, b1, x) + relu(w2, b2, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"Som van 2 ReLUs\")\n",
    "    \n",
    "    plotCurve(x, fit, False)\n",
    "    plotCurve(x, yNoise, True)\n",
    "    \n",
    "    showPlot()\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Inital cost\n",
    "mse = cost(w1Fit, b1Fit, w2Fit, b2Fit)\n",
    "\n",
    "print(\"initial cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "epochList = []\n",
    "costList = []\n",
    "\n",
    "while epoch < epochs:\n",
    "    \n",
    "    # print(\"epoch: \", epoch)\n",
    "    \n",
    "    epochList.append(epoch)\n",
    "    \n",
    "    w1Fit, b1Fit, w2Fit, b2Fit = gradientDescent(w1Fit, b1Fit, w2Fit, b2Fit)\n",
    "    \n",
    "    # print(\"cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "    \n",
    "    costList.append(cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "#------------------------------------------\n",
    "\n",
    "print(\"w1Fit: \", w1Fit, \"b1Fit: \", b1Fit, \"w2Fit: \", w2Fit, \"b2Fit: \", b2Fit)\n",
    "print(\"final cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "\n",
    "plotFit(w1Fit, b1Fit, w2Fit, b2Fit)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel='epoch', ylabel='cost', title=\"Cost function\")\n",
    "\n",
    "plt.plot(epochList, costList, 'red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
